{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2f79591-d1a0-44d5-b219-5a067c9f91ab",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Databricks-BR/lab_sql/main/images/header_notebook.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5af31e35-6373-417e-99d3-bfb57c499fd2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Referencias\n",
    "* [Lectura de archivos CSV](https://learn.microsoft.com/pt-br/azure/databricks/external-data/csv)\n",
    "* [Notebook Ejemplo - CSV](https://docs.databricks.com/_extras/notebooks/source/read-csv-files.html)\n",
    "* [Guardar en una tabla DELTA](https://docs.databricks.com/delta/tutorial.html#create-a-table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05476df0-f786-4202-8ebe-2c2e500320ea",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Parámetros iniciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a467ff1-53c5-45b2-9767-abdc27d98f09",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "url = f\"https://raw.githubusercontent.com//pieroocampo/lab_sql/main/datos/\"\n",
    "prefix_table = f\"bronze\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b80f9d7c-8154-4ac8-a298-412b4c487624",
     "showTitle": true,
     "title": "MODIFICA ESTE PRARÁMETRO"
    }
   },
   "outputs": [],
   "source": [
    "#schema_name  = f\"<<<<<-----Coloca tu nombre de usuario aquí --------->>>>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%python\n",
    "spark.sql(\"CREATE DATABASE {}\".format(schema_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2be65657-c09a-405d-9786-4542f6858c39",
     "showTitle": true,
     "title": "Guardando a tabla Delta - dolar"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "entity_name  = f\"dolar\"\n",
    "\n",
    "table_name   = f\"{schema_name}.{prefix_table}_{entity_name}\"\n",
    "file_name = f\"{url}{entity_name}.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name)                          # Lectura de archivo CSV utilizando Dataframe Pandas\n",
    "s_df = spark.createDataFrame(df)                     # Convertir Dataframe Pandas en Spark Dataframe\n",
    "s_df.write.mode(\"overwrite\").saveAsTable(table_name) # Guardar DataFrame como Tabela Delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23edce93-c276-4bc2-ad08-d9379e9ba226",
     "showTitle": true,
     "title": "Guardando a tabla Delta - CNAE"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "entity_name  = f\"cnae\"\n",
    "\n",
    "table_name   = f\"{schema_name}.{prefix_table}_{entity_name}\"\n",
    "file_name = f\"{url}{entity_name}.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name)                          # Lectura de archivo CSV utilizando Dataframe Pandas\n",
    "s_df = spark.createDataFrame(df)                     # Convertir Dataframe Pandas en Spark Dataframek Dataframe\n",
    "s_df.write.mode(\"overwrite\").saveAsTable(table_name) # Guardar DataFrame como Tabela Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5eb8337-343e-49fe-a29f-7716eca07c2d",
     "showTitle": true,
     "title": "Guardando a tabla Delta - empresas"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "entity_name  = f\"empresas\"\n",
    "\n",
    "table_name   = f\"{schema_name}.{prefix_table}_{entity_name}\"\n",
    "file_name = f\"{url}{entity_name}.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name)                          # Lectura de archivo CSV utilizando Dataframe Pandas\n",
    "s_df = spark.createDataFrame(df)                     # Convertir Dataframe Pandas en Spark Dataframe\n",
    "s_df.write.mode(\"overwrite\").saveAsTable(table_name) # Guardar DataFrame como Tabela Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32069678-7caf-4318-8a95-af8f6438263e",
     "showTitle": true,
     "title": "Guardando a tabla Delta - establecimientos"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "entity_name  = f\"establecimentos\"\n",
    "\n",
    "table_name   = f\"{schema_name}.{prefix_table}_{entity_name}\"\n",
    "file_name = f\"{url}{entity_name}.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name)                          # Lectura de archivo CSV utilizando Dataframe Pandas\n",
    "s_df = spark.createDataFrame(df)                     # Convertir Dataframe Pandas en Spark Dataframe\n",
    "s_df.write.mode(\"overwrite\").saveAsTable(table_name) # Guardar DataFrame como Tabela Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d016c9fb-f538-4534-9897-7b20478a541f",
     "showTitle": true,
     "title": "Guardando a tabla Delta - municipios"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "entity_name  = f\"municipios\"\n",
    "\n",
    "table_name   = f\"{schema_name}.{prefix_table}_{entity_name}\"\n",
    "file_name = f\"{url}{entity_name}.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name)                          # Lectura de archivo CSV utilizando Dataframe Pandas\n",
    "s_df = spark.createDataFrame(df)                     # Convertir Dataframe Pandas en Spark Dataframe\n",
    "s_df.write.mode(\"overwrite\").saveAsTable(table_name) # Guardar DataFrame como Tabela Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c90d01b9-0277-4c05-a443-9153262331cb",
     "showTitle": true,
     "title": "Guardando a tabla Delta - giros"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "entity_name  = f\"giros\"\n",
    "\n",
    "table_name   = f\"{schema_name}.{prefix_table}_{entity_name}\"\n",
    "file_name = f\"{url}{entity_name}.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name)                          # Lectura de archivo CSV utilizando Dataframe Pandas\n",
    "s_df = spark.createDataFrame(df)                     # Convertir Dataframe Pandas en Spark Dataframe\n",
    "s_df.write.mode(\"overwrite\").saveAsTable(table_name) # Guardar DataFrame como Tabela Delta"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 597306790085131,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "lab02_01_carga_csv",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
